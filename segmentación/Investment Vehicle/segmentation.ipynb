{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a73a3fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinso\\AppData\\Local\\Temp\\ipykernel_34352\\538391796.py:101: DtypeWarning: Columns (70,71) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(TX_PATH, encoding=\"utf-8-sig\", dtype={\"customer_id\":\"string\"})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clientes elegibles por ÚLTIMA tx en 'Investment Vehicle': 2,504\n",
      "Transacciones Investment Vehicle (por última tx): 18,649 | Clientes: 2,504 | Direcciones: {'Outbound': 12451, 'Inbound': 6198}\n",
      "\n",
      "=== Métricas por k ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>silhouette</th>\n",
       "      <th>dbi</th>\n",
       "      <th>inertia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.981668</td>\n",
       "      <td>0.241782</td>\n",
       "      <td>54,274.349473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.941069</td>\n",
       "      <td>0.560746</td>\n",
       "      <td>27,609.273625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.940742</td>\n",
       "      <td>0.398141</td>\n",
       "      <td>25,295.054234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.937278</td>\n",
       "      <td>0.356328</td>\n",
       "      <td>21,674.333045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k  silhouette      dbi       inertia\n",
       "0  2    0.981668 0.241782 54,274.349473\n",
       "1  3    0.941069 0.560746 27,609.273625\n",
       "2  4    0.940742 0.398141 25,295.054234\n",
       "3  5    0.937278 0.356328 21,674.333045"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "k elegido: 2 | distribución (% clientes): {'IV-1': 99.9, 'IV-2': 0.1}\n",
      "\n",
      "=== Perfiles por subsegmento ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clients</th>\n",
       "      <th>share_clients</th>\n",
       "      <th>med_monthly_out</th>\n",
       "      <th>mean_monthly_out</th>\n",
       "      <th>med_tx_month_out</th>\n",
       "      <th>mean_tx_month_out</th>\n",
       "      <th>med_monthly_in</th>\n",
       "      <th>mean_monthly_in</th>\n",
       "      <th>med_tx_month_in</th>\n",
       "      <th>mean_tx_month_in</th>\n",
       "      <th>med_ticket_out</th>\n",
       "      <th>mean_ticket_out</th>\n",
       "      <th>med_ticket_in</th>\n",
       "      <th>mean_ticket_in</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IV-1</th>\n",
       "      <td>2502</td>\n",
       "      <td>99.92</td>\n",
       "      <td>12,218,453</td>\n",
       "      <td>91,912,351.95</td>\n",
       "      <td>1</td>\n",
       "      <td>1.56</td>\n",
       "      <td>3,025,240</td>\n",
       "      <td>94,203,413.33</td>\n",
       "      <td>1</td>\n",
       "      <td>0.89</td>\n",
       "      <td>7,056,958.5</td>\n",
       "      <td>51,171,303.42</td>\n",
       "      <td>2,000,000</td>\n",
       "      <td>59,246,233.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IV-2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.08</td>\n",
       "      <td>18,870,441,882</td>\n",
       "      <td>18,870,441,882</td>\n",
       "      <td>8.75</td>\n",
       "      <td>8.75</td>\n",
       "      <td>15,159,600,000</td>\n",
       "      <td>15,159,600,000</td>\n",
       "      <td>17.62</td>\n",
       "      <td>17.62</td>\n",
       "      <td>1,316,136,911.75</td>\n",
       "      <td>1,316,136,911.75</td>\n",
       "      <td>842,850,000</td>\n",
       "      <td>842,850,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               clients  share_clients  med_monthly_out  mean_monthly_out  \\\n",
       "segment_label                                                              \n",
       "IV-1              2502          99.92       12,218,453     91,912,351.95   \n",
       "IV-2                 2           0.08   18,870,441,882    18,870,441,882   \n",
       "\n",
       "               med_tx_month_out  mean_tx_month_out  med_monthly_in  \\\n",
       "segment_label                                                        \n",
       "IV-1                          1               1.56       3,025,240   \n",
       "IV-2                       8.75               8.75  15,159,600,000   \n",
       "\n",
       "               mean_monthly_in  med_tx_month_in  mean_tx_month_in  \\\n",
       "segment_label                                                       \n",
       "IV-1             94,203,413.33                1              0.89   \n",
       "IV-2            15,159,600,000            17.62             17.62   \n",
       "\n",
       "                med_ticket_out  mean_ticket_out  med_ticket_in  mean_ticket_in  \n",
       "segment_label                                                                   \n",
       "IV-1               7,056,958.5    51,171,303.42      2,000,000   59,246,233.31  \n",
       "IV-2          1,316,136,911.75 1,316,136,911.75    842,850,000     842,850,000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Pipeline de subsegmentación por segmento (generalizado) ===================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "import math\n",
    "pd.set_option(\"display.float_format\",\n",
    "              lambda v: f\"{v:,.6f}\".rstrip(\"0\").rstrip(\".\"))  # hasta 6 decimales, sin ceros de sobra\n",
    "np.set_printoptions(suppress=True,\n",
    "                    formatter={\"float_kind\": lambda v: f\"{v:,.6f}\".rstrip(\"0\").rstrip(\".\")})\n",
    "\n",
    "# ------------------------ PARÁMETROS EDITABLES ---------------------------------\n",
    "TX_PATH        = Path(\"../../data/tx/transacciones_cash_2025.csv\")  # CSV maestro\n",
    "SEGMENT_NAME   = \"Investment Vehicle\"                             # <- segmento objetivo (customer_sub_type)\n",
    "FOCUS_TX_TYPE  = \"Cash\"                               # tipo de transacción\n",
    "DIRECTIONS     = [\"Inbound\", \"Outbound\"]              # direcciones a considerar\n",
    "PERIOD_START   = None                                 # ej: \"2024-01-01\" o None para no filtrar por fecha\n",
    "SCALER_KIND    = \"robust\"\n",
    "\n",
    "# Variables candidatas\n",
    "FEATURES = [\n",
    "    \"median_monthly_out\", \"tx_per_active_month_out\",\n",
    "    \"median_monthly_in\",  \"tx_per_active_month_in\",\n",
    "    \"median_amount_out\",  \"median_amount_in\",\n",
    "]\n",
    "\n",
    "# Candidatos de k para búsqueda y elbow\n",
    "K_CANDIDATES   = [2, 3, 4, 5]\n",
    "ELBOW_MAX_K    = 6\n",
    "RANDOM_STATE   = 42\n",
    "\n",
    "# Criterio simple para decidir si conviene subsegmentar\n",
    "MIN_CLIENTS_FOR_CLUSTER = 30       # mínimo de clientes para intentar clusterizar\n",
    "SILHOUETTE_OK_THRESHOLD = 0.18     # si el mejor silhouette < umbral -> no segmentar\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# ------------------------ HELPERS -----------------------------\n",
    "def _clean_headers(cols):\n",
    "    out = []\n",
    "    for c in cols:\n",
    "        c = str(c)\n",
    "        c = c.strip().strip(\"'\\\"\")\n",
    "        c = c.rstrip(\";\")\n",
    "        out.append(c)\n",
    "    return out\n",
    "\n",
    "def _to_datetime(s):\n",
    "    return pd.to_datetime(s, errors=\"coerce\")\n",
    "\n",
    "def _to_numeric(s):\n",
    "    return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "def per_dir_ticket(tdf):\n",
    "    g = tdf.groupby(\"customer_id\", as_index=False)\n",
    "    f = g.agg(\n",
    "        median_amount=(\"tx_base_amount\",\"median\"),\n",
    "        p95_amount=(\"tx_base_amount\", lambda s: np.nanpercentile(s,95)),\n",
    "        q75=(\"tx_base_amount\", lambda s: np.nanpercentile(s,75)),\n",
    "        q25=(\"tx_base_amount\", lambda s: np.nanpercentile(s,25)),\n",
    "        n_tx=(\"tx_id\",\"count\")\n",
    "    )\n",
    "    f[\"iqr_amount\"] = (f[\"q75\"] - f[\"q25\"]).clip(lower=0)\n",
    "    f[\"spiky_tx_ratio\"] = f[\"p95_amount\"] / f[\"median_amount\"].replace(0,np.nan)\n",
    "    f[\"spiky_tx_ratio\"] = f[\"spiky_tx_ratio\"].fillna(np.inf)\n",
    "    f[\"log_median_amount\"] = np.log1p(f[\"median_amount\"])\n",
    "    return f\n",
    "\n",
    "def per_dir_monthly(tdf):\n",
    "    tdf = tdf.copy()\n",
    "    tdf[\"ym\"] = tdf[\"tx_date_time\"].dt.to_period(\"M\")\n",
    "    m = tdf.groupby([\"customer_id\",\"ym\"], as_index=False).agg(\n",
    "        month_total=(\"tx_base_amount\",\"sum\"),\n",
    "        month_n_tx=(\"tx_id\",\"count\")\n",
    "    )\n",
    "    f = (m.groupby(\"customer_id\", as_index=False)\n",
    "           .agg(\n",
    "               active_months=(\"ym\",\"nunique\"),\n",
    "               tx_per_active_month=(\"month_n_tx\",\"mean\"),\n",
    "               median_monthly=(\"month_total\",\"median\"),\n",
    "               p75_monthly=(\"month_total\", lambda s: np.nanpercentile(s,75)),\n",
    "               monthly_cv=(\"month_total\", lambda s: np.nanstd(s)/np.nanmean(s) if np.nanmean(s) else np.nan)\n",
    "           ))\n",
    "    f[\"log_median_monthly\"] = np.log1p(f[\"median_monthly\"])\n",
    "    return f\n",
    "\n",
    "def add_suffix_keep_key(df_, suffix, key=\"customer_id\"):\n",
    "    if df_.empty:\n",
    "        return pd.DataFrame({key: pd.Series([], dtype=str)})\n",
    "    df_ = df_.copy()\n",
    "    cols = {c: f\"{c}{suffix}\" for c in df_.columns if c != key}\n",
    "    return df_.rename(columns=cols)\n",
    "\n",
    "def _abbr(name, default=\"SEG\"):\n",
    "    tok = \"\".join([t[0] for t in str(name).split() if t])\n",
    "    return (tok or default).upper()\n",
    "\n",
    "# ------------------------ CARGA + LIMPIEZA ------------------------------\n",
    "df = pd.read_csv(TX_PATH, encoding=\"utf-8-sig\", dtype={\"customer_id\":\"string\"})\n",
    "df.columns = _clean_headers(df.columns)\n",
    "\n",
    "for col in df.select_dtypes(include=\"object\").columns:\n",
    "    df[col] = (df[col].astype(str)\n",
    "                     .str.replace(r'^[\\'\"]|[\\'\"]$', '', regex=True)\n",
    "                     .str.replace(r';+$', '', regex=True)\n",
    "                     .str.strip())\n",
    "\n",
    "# parseos\n",
    "if \"tx_date_time\" in df.columns:\n",
    "    df[\"tx_date_time\"] = _to_datetime(df[\"tx_date_time\"])\n",
    "if \"tx_base_amount\" in df.columns:\n",
    "    df[\"tx_base_amount\"] = _to_numeric(df[\"tx_base_amount\"])\n",
    "\n",
    "required_cols = [\"tx_id\",\"tx_type\",\"tx_direction\",\"customer_sub_type\",\n",
    "                 \"customer_id\",\"customer_name\",\"tx_date_time\",\"tx_base_amount\"]\n",
    "missing = [c for c in required_cols if c not in df.columns]\n",
    "if missing:\n",
    "    raise AssertionError(f\"Faltan columnas {missing}. Presentes: {list(df.columns)}\")\n",
    "\n",
    "# ------------------------ FILTRO SEGMENTO (por ÚLTIMA TX del cliente) ----------\n",
    "# 1) Pre-filtro mínimo para determinar la última tx por cliente:\n",
    "#    (solo aseguramos tener fecha; NO restringimos por sub_type todavía)\n",
    "df_last_base = df.dropna(subset=[\"customer_id\", \"tx_date_time\"]).copy()\n",
    "df_last_base[\"customer_id\"] = df_last_base[\"customer_id\"].astype(str).str.strip()\n",
    "\n",
    "# 2) Orden temporal y \"último sub_type conocido\" por cliente\n",
    "#    - Si la última fila tiene NaN en sub_type pero hubo una previa con valor, tomamos la última conocida (ffill)\n",
    "df_last_base = df_last_base.sort_values([\"customer_id\", \"tx_date_time\"])\n",
    "df_last_base[\"subtype_last_known\"] = (\n",
    "    df_last_base.groupby(\"customer_id\", group_keys=False)[\"customer_sub_type\"].ffill()\n",
    ")\n",
    "\n",
    "# 3) Tomamos la ÚLTIMA fila por cliente (máxima fecha)\n",
    "last_rows = df_last_base.groupby(\"customer_id\", as_index=False).tail(1)\n",
    "\n",
    "# 4) Elegibles = clientes cuyo sub_type de la última tx (conocido) es el segmento objetivo\n",
    "eligible_ids = last_rows.loc[\n",
    "    last_rows[\"subtype_last_known\"].astype(str).str.upper() == str(SEGMENT_NAME).upper(),\n",
    "    \"customer_id\"\n",
    "].unique()\n",
    "\n",
    "print(f\"Clientes elegibles por ÚLTIMA tx en '{SEGMENT_NAME}': {len(eligible_ids):,}\")\n",
    "\n",
    "# 5) Ahora sí armamos el dataset de transacciones con:\n",
    "#    - SOLO esos clientes elegibles\n",
    "#    - Cash + direcciones indicadas\n",
    "#    - (Opcional) PERIOD_START si quieres trabajar un período específico para features\n",
    "mask = (\n",
    "    df[\"customer_id\"].astype(str).str.strip().isin(eligible_ids) &\n",
    "    df[\"tx_type\"].str.upper().eq(str(FOCUS_TX_TYPE).upper()) &\n",
    "    df[\"tx_direction\"].isin(DIRECTIONS)\n",
    ")\n",
    "if PERIOD_START:\n",
    "    start_dt = pd.to_datetime(PERIOD_START)\n",
    "    mask &= df[\"tx_date_time\"].ge(start_dt)\n",
    "\n",
    "tx = df.loc[mask].copy()\n",
    "tx = tx.dropna(subset=[\"customer_id\"])\n",
    "tx[\"customer_id\"] = tx[\"customer_id\"].astype(str).str.strip()\n",
    "\n",
    "n_clients = tx[\"customer_id\"].nunique()\n",
    "print(f\"Transacciones {SEGMENT_NAME} (por última tx): {len(tx):,} | Clientes: {n_clients:,} | Direcciones: {tx['tx_direction'].value_counts().to_dict()}\")\n",
    "\n",
    "if n_clients < MIN_CLIENTS_FOR_CLUSTER:\n",
    "    print(f\"\\ Pocos clientes ({n_clients}) para clusterizar (mínimo {MIN_CLIENTS_FOR_CLUSTER}). No se subsegmenta.\")\n",
    "else:\n",
    "    # ------------------------ FEATURES--------------------\n",
    "    tx_out = tx[tx[\"tx_direction\"]==\"Outbound\"].copy()\n",
    "    tx_in  = tx[tx[\"tx_direction\"]==\"Inbound\"].copy()\n",
    "\n",
    "    base = (tx.groupby(\"customer_id\", as_index=False)\n",
    "              .agg(customer_name=(\"customer_name\",\"last\"),\n",
    "                   first_tx=(\"tx_date_time\",\"min\"),\n",
    "                   last_tx=(\"tx_date_time\",\"max\")))\n",
    "\n",
    "    f_out_tx  = add_suffix_keep_key(per_dir_ticket(tx_out),   \"_out\")\n",
    "    f_out_mon = add_suffix_keep_key(per_dir_monthly(tx_out),  \"_out\")\n",
    "    f_in_tx   = add_suffix_keep_key(per_dir_ticket(tx_in),    \"_in\")\n",
    "    f_in_mon  = add_suffix_keep_key(per_dir_monthly(tx_in),   \"_in\")\n",
    "\n",
    "    feat = (base\n",
    "            .merge(f_out_tx,  on=\"customer_id\", how=\"left\")\n",
    "            .merge(f_out_mon, on=\"customer_id\", how=\"left\")\n",
    "            .merge(f_in_tx,   on=\"customer_id\", how=\"left\")\n",
    "            .merge(f_in_mon,  on=\"customer_id\", how=\"left\"))\n",
    "\n",
    "    feat.rename(columns={\n",
    "        \"log_median_amount_out\":   \"log_median_out_amount\",\n",
    "        \"log_median_monthly_out\":  \"log_median_monthly_out\",\n",
    "        \"log_median_amount_in\":    \"log_median_in_amount\",\n",
    "        \"log_median_monthly_in\":   \"log_median_monthly_in\",\n",
    "    }, inplace=True)\n",
    "\n",
    "    fill_cols = [\n",
    "        \"median_monthly_out\",\"tx_per_active_month_out\",\"monthly_cv_out\",\n",
    "        \"median_amount_out\",\"p95_amount_out\",\"iqr_amount_out\",\n",
    "        \"median_monthly_in\",\"tx_per_active_month_in\",\"monthly_cv_in\",\n",
    "        \"median_amount_in\",\"p95_amount_in\",\"iqr_amount_in\",\n",
    "        \"log_median_monthly_out\",\"log_median_out_amount\",\n",
    "        \"log_median_monthly_in\",\"log_median_in_amount\"\n",
    "    ]\n",
    "    for c in fill_cols:\n",
    "        if c in feat.columns:\n",
    "            feat[c] = pd.to_numeric(feat[c], errors=\"coerce\").fillna(0)\n",
    "\n",
    "    # ------------------------ MATRIZ X + ESCALADO -----------------------------\n",
    "    X = feat[FEATURES].copy()\n",
    "    if SCALER_KIND.lower() == \"standard\":\n",
    "        scaler = StandardScaler()\n",
    "    else:\n",
    "        scaler = RobustScaler(quantile_range=(10,90))\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # ------------------------ BÚSQUEDA DE k -----------------------------------\n",
    "    results = []\n",
    "    for k in K_CANDIDATES:\n",
    "        try:\n",
    "            km = KMeans(n_clusters=k, random_state=RANDOM_STATE, n_init=\"auto\")\n",
    "            labels = km.fit_predict(X_scaled)\n",
    "            sil = silhouette_score(X_scaled, labels) if k > 1 else np.nan\n",
    "            dbi = davies_bouldin_score(X_scaled, labels) if k > 1 else np.nan\n",
    "            inertia = km.inertia_\n",
    "            results.append({\"k\": k, \"silhouette\": sil, \"dbi\": dbi, \"inertia\": inertia})\n",
    "        except Exception as e:\n",
    "            results.append({\"k\": k, \"silhouette\": np.nan, \"dbi\": np.nan, \"inertia\": np.nan, \"err\": str(e)})\n",
    "\n",
    "    res = pd.DataFrame(results).sort_values(\"k\")\n",
    "    print(\"\\n=== Métricas por k ===\")\n",
    "    display(res)\n",
    "\n",
    "    # Decisión: ¿vale la pena subsegmentar?\n",
    "    res_clean = res.dropna(subset=[\"silhouette\",\"dbi\"])\n",
    "    if res_clean.empty or (res_clean[\"silhouette\"].max() < SILHOUETTE_OK_THRESHOLD):\n",
    "        print(f\"\\n No se observa estructura fuerte (mejor silhouette < {SILHOUETTE_OK_THRESHOLD}).\")\n",
    "        print(\" Recomendación: NO subsegmentar este segmento por ahora.\")\n",
    "    else:\n",
    "        # -------------------- Fit final y renombrado --------------------------\n",
    "        BEST_K = int(res_clean.sort_values([\"silhouette\",\"dbi\"], ascending=[False,True]).iloc[0][\"k\"])\n",
    "        km = KMeans(n_clusters=BEST_K, random_state=RANDOM_STATE, n_init=\"auto\")\n",
    "        feat[\"cluster_raw\"] = km.fit_predict(X_scaled)\n",
    "\n",
    "        order_key = (feat.groupby(\"cluster_raw\")\n",
    "                       .agg(rank_key=(\"median_monthly_out\",\"median\"),\n",
    "                            rank_key2=(\"median_monthly_in\",\"median\"))\n",
    "                       .sort_values([\"rank_key\",\"rank_key2\"])\n",
    "                       .reset_index())\n",
    "        order_map = {raw:i for i, raw in enumerate(order_key[\"cluster_raw\"])}\n",
    "        feat[\"cluster_ord\"] = feat[\"cluster_raw\"].map(order_map)\n",
    "\n",
    "        # Etiquetas amigables\n",
    "        prefix = _abbr(SEGMENT_NAME)\n",
    "        if BEST_K == 3:\n",
    "            names = {0:\"Low\", 1:\"Mid\", 2:\"High\"}\n",
    "            label_names = {i: f\"{prefix}-{names.get(i,i)}\" for i in range(BEST_K)}\n",
    "        else:\n",
    "            label_names = {i: f\"{prefix}-{i+1}\" for i in range(BEST_K)}\n",
    "\n",
    "        feat[\"segment_label\"] = feat[\"cluster_ord\"].map(label_names)\n",
    "\n",
    "        dist = feat[\"segment_label\"].value_counts(normalize=True).mul(100).round(1).to_dict()\n",
    "        print(f\"\\nk elegido: {BEST_K} | distribución (% clientes): {dist}\")\n",
    "\n",
    "        summary = (\n",
    "            feat.groupby(\"segment_label\", dropna=False)\n",
    "                .agg(\n",
    "                    clients=(\"customer_id\",\"nunique\"),\n",
    "                    share_clients=(\"customer_id\", lambda s: 100*s.nunique()/feat[\"customer_id\"].nunique()),\n",
    "                    med_monthly_out=(\"median_monthly_out\",\"median\"),\n",
    "                    mean_monthly_out=(\"median_monthly_out\",\"mean\"),\n",
    "                    med_tx_month_out=(\"tx_per_active_month_out\",\"median\"),\n",
    "                    mean_tx_month_out=(\"tx_per_active_month_out\",\"mean\"),\n",
    "                    med_monthly_in=(\"median_monthly_in\",\"median\"),\n",
    "                    mean_monthly_in=(\"median_monthly_in\",\"mean\"),\n",
    "                    med_tx_month_in=(\"tx_per_active_month_in\",\"median\"),\n",
    "                    mean_tx_month_in=(\"tx_per_active_month_in\",\"mean\"),\n",
    "                    med_ticket_out=(\"median_amount_out\",\"median\"),\n",
    "                    mean_ticket_out=(\"median_amount_out\",\"mean\"),\n",
    "                    med_ticket_in=(\"median_amount_in\",\"median\"),\n",
    "                    mean_ticket_in=(\"median_amount_in\",\"mean\"),\n",
    "                )\n",
    "                .sort_values([\"med_monthly_out\",\"med_monthly_in\"])\n",
    "                .round(2)\n",
    "        )\n",
    "        print(\"\\n=== Perfiles por subsegmento ===\")\n",
    "        display(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b88538f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo creado: ..\\..\\data\\new_segments\\investment_vehicle_segments.csv | Filas: 2,504\n"
     ]
    }
   ],
   "source": [
    "# === Exportar mapping con métricas extendidas (incluye #tx mensuales) =========\n",
    "from pathlib import Path\n",
    "\n",
    "# 1) Helpers de estadísticos ---------------------------------------------------\n",
    "def _quantiles(series, qs=(25, 50, 75, 95)):\n",
    "    s = pd.to_numeric(series, errors=\"coerce\").dropna()\n",
    "    if s.empty:\n",
    "        return {q: np.nan for q in qs}\n",
    "    vals = np.nanpercentile(s, qs)\n",
    "    return {q: v for q, v in zip(qs, vals)}\n",
    "\n",
    "def ticket_stats(tdf, suffix):\n",
    "    \"\"\"Estadísticos por cliente a nivel de transacción (ticket), por dirección.\"\"\"\n",
    "    if tdf.empty:\n",
    "        return pd.DataFrame({\"customer_id\": pd.Series([], dtype=str)})\n",
    "    g = (tdf.groupby(\"customer_id\")\n",
    "            .agg(\n",
    "                amount_min=(\"tx_base_amount\", \"min\"),\n",
    "                amount_max=(\"tx_base_amount\", \"max\"),\n",
    "                amount_mean=(\"tx_base_amount\", \"mean\"),\n",
    "                amount_p25=(\"tx_base_amount\", lambda s: _quantiles(s,[25])[25]),\n",
    "                amount_median=(\"tx_base_amount\", lambda s: _quantiles(s,[50])[50]),\n",
    "                amount_p75=(\"tx_base_amount\", lambda s: _quantiles(s,[75])[75]),\n",
    "                amount_p95=(\"tx_base_amount\", lambda s: _quantiles(s,[95])[95]),\n",
    "            )\n",
    "          .reset_index())\n",
    "    g[\"amount_p75_minus_median\"]   = g[\"amount_p75\"]   - g[\"amount_median\"]\n",
    "    g[\"amount_median_minus_p25\"]   = g[\"amount_median\"] - g[\"amount_p25\"]\n",
    "    rename_map = {c: f\"{c}_{suffix}\" for c in g.columns if c != \"customer_id\"}\n",
    "    return g.rename(columns=rename_map)\n",
    "\n",
    "def monthly_stats(tdf, suffix):\n",
    "    \"\"\"\n",
    "    Estadísticos por cliente a nivel mensual (suma por mes) + número de transacciones/mes,\n",
    "    por dirección.\n",
    "    \"\"\"\n",
    "    if tdf.empty:\n",
    "        return pd.DataFrame({\"customer_id\": pd.Series([], dtype=str)})\n",
    "\n",
    "    t = tdf.copy()\n",
    "    t[\"ym\"] = t[\"tx_date_time\"].dt.to_period(\"M\")\n",
    "    m = (t.groupby([\"customer_id\",\"ym\"], as_index=False)\n",
    "           .agg(month_total=(\"tx_base_amount\",\"sum\"),\n",
    "                month_n_tx=(\"tx_id\",\"count\")))\n",
    "\n",
    "    g = (m.groupby(\"customer_id\")\n",
    "          .agg(\n",
    "              # Montos mensuales\n",
    "              monthly_min=(\"month_total\",\"min\"),\n",
    "              monthly_max=(\"month_total\",\"max\"),\n",
    "              monthly_mean=(\"month_total\",\"mean\"),\n",
    "              monthly_p25=(\"month_total\", lambda s: _quantiles(s,[25])[25]),\n",
    "              monthly_median=(\"month_total\", lambda s: _quantiles(s,[50])[50]),\n",
    "              monthly_p75=(\"month_total\", lambda s: _quantiles(s,[75])[75]),\n",
    "              monthly_p95=(\"month_total\", lambda s: _quantiles(s,[95])[95]),\n",
    "              # # de transacciones mensuales\n",
    "              tx_monthly_min=(\"month_n_tx\",\"min\"),\n",
    "              tx_monthly_max=(\"month_n_tx\",\"max\"),\n",
    "              tx_monthly_mean=(\"month_n_tx\",\"mean\"),\n",
    "              tx_monthly_p25=(\"month_n_tx\", lambda s: _quantiles(s,[25])[25]),\n",
    "              tx_monthly_median=(\"month_n_tx\", lambda s: _quantiles(s,[50])[50]),\n",
    "              tx_monthly_p75=(\"month_n_tx\", lambda s: _quantiles(s,[75])[75]),\n",
    "              tx_monthly_p95=(\"month_n_tx\", lambda s: _quantiles(s,[95])[95]),\n",
    "              # Promedio de tx por mes activo (igual a tx_per_active_month ya usado)\n",
    "              tx_per_active_month=(\"month_n_tx\",\"mean\"),\n",
    "              # Meses activos por registro\n",
    "              active_months=(\"ym\",\"nunique\"),\n",
    "          )\n",
    "          .reset_index())\n",
    "\n",
    "    # Deltas para montos mensuales\n",
    "    g[\"monthly_p75_minus_median\"] = g[\"monthly_p75\"] - g[\"monthly_median\"]\n",
    "    g[\"monthly_median_minus_p25\"] = g[\"monthly_median\"] - g[\"monthly_p25\"]\n",
    "    # Deltas para #tx mensuales\n",
    "    g[\"tx_monthly_p75_minus_median\"] = g[\"tx_monthly_p75\"] - g[\"tx_monthly_median\"]\n",
    "    g[\"tx_monthly_median_minus_p25\"] = g[\"tx_monthly_median\"] - g[\"tx_monthly_p25\"]\n",
    "\n",
    "    rename_map = {c: f\"{c}_{suffix}\" for c in g.columns if c != \"customer_id\"}\n",
    "    return g.rename(columns=rename_map)\n",
    "\n",
    "# 2) Estadísticos OUT/IN a partir de las mismas tx filtradas -------------------\n",
    "tick_out = ticket_stats(tx_out, \"out\")\n",
    "tick_in  = ticket_stats(tx_in,  \"in\")\n",
    "mon_out  = monthly_stats(tx_out, \"out\")\n",
    "mon_in   = monthly_stats(tx_in,  \"in\")\n",
    "\n",
    "# 3) Ensamble por cliente (solo clientes segmentados) --------------------------\n",
    "segmented = feat.loc[feat[\"segment_label\"].notna(), [\n",
    "    \"customer_id\",\"customer_name\",\"segment_label\",\n",
    "    \"median_monthly_out\",\"tx_per_active_month_out\",\"median_amount_out\",\n",
    "    \"median_monthly_in\",\"tx_per_active_month_in\",\"median_amount_in\",\n",
    "    \"first_tx\",\"last_tx\"\n",
    "]].copy()\n",
    "\n",
    "export_df = (segmented\n",
    "             .merge(tick_out, on=\"customer_id\", how=\"left\")\n",
    "             .merge(tick_in,  on=\"customer_id\", how=\"left\")\n",
    "             .merge(mon_out,  on=\"customer_id\", how=\"left\")\n",
    "             .merge(mon_in,   on=\"customer_id\", how=\"left\"))\n",
    "\n",
    "# 4) Reordenar/renombrar columnas según pedido --------------------------------\n",
    "ordered_cols = [\n",
    "    \"customer_id\",\"customer_name\",\"segment_label\",\n",
    "    \"median_monthly_out\",\"tx_per_active_month_out\",\"median_amount_out\",\n",
    "    \"median_monthly_in\",\"tx_per_active_month_in\",\"median_amount_in\",\n",
    "    \"first_tx\",\"last_tx\",\n",
    "\n",
    "    # ------- Ticket OUT -------\n",
    "    \"amount_max_out\",\"amount_p75_out\",\"amount_p75_minus_median_out\",\n",
    "    \"amount_median_minus_p25_out\",\"amount_p25_out\",\"amount_median_out\",\n",
    "    \"amount_min_out\",\"amount_mean_out\",\"amount_p95_out\",\n",
    "\n",
    "    # ------- Ticket IN -------\n",
    "    \"amount_max_in\",\"amount_p75_in\",\"amount_p75_minus_median_in\",\n",
    "    \"amount_median_minus_p25_in\",\"amount_p25_in\",\"amount_median_in\",\n",
    "    \"amount_min_in\",\"amount_mean_in\",\"amount_p95_in\",\n",
    "\n",
    "    # ------- Monthly amounts OUT -------\n",
    "    \"monthly_max_out\",\"monthly_p75_out\",\"monthly_p75_minus_median_out\",\n",
    "    \"monthly_median_minus_p25_out\",\"monthly_p25_out\",\"monthly_median_out\",\n",
    "    \"monthly_min_out\",\"monthly_mean_out\",\"monthly_p95_out\",\n",
    "\n",
    "    # ------- Monthly amounts IN -------\n",
    "    \"monthly_max_in\",\"monthly_p75_in\",\"monthly_p75_minus_median_in\",\n",
    "    \"monthly_median_minus_p25_in\",\"monthly_p25_in\",\"monthly_median_in\",\n",
    "    \"monthly_min_in\",\"monthly_mean_in\",\"monthly_p95_in\",\n",
    "\n",
    "    # ------- Monthly #tx OUT -------\n",
    "    \"tx_monthly_max_out\",\"tx_monthly_p75_out\",\"tx_monthly_p75_minus_median_out\",\n",
    "    \"tx_monthly_median_minus_p25_out\",\"tx_monthly_p25_out\",\"tx_monthly_median_out\",\n",
    "    \"tx_monthly_min_out\",\"tx_monthly_mean_out\",\"tx_monthly_p95_out\",\n",
    "    \"tx_per_active_month_out\",\"active_months_out\",\n",
    "\n",
    "    # ------- Monthly #tx IN -------\n",
    "    \"tx_monthly_max_in\",\"tx_monthly_p75_in\",\"tx_monthly_p75_minus_median_in\",\n",
    "    \"tx_monthly_median_minus_p25_in\",\"tx_monthly_p25_in\",\"tx_monthly_median_in\",\n",
    "    \"tx_monthly_min_in\",\"tx_monthly_mean_in\",\"tx_monthly_p95_in\",\n",
    "    \"tx_per_active_month_in\",\"active_months_in\",\n",
    "]\n",
    "\n",
    "# Mantener solo columnas existentes (por si algún lado no tiene datos)\n",
    "ordered_cols = [c for c in ordered_cols if c in export_df.columns]\n",
    "export_df = export_df[ordered_cols].copy()\n",
    "\n",
    "# 5) Exportar a CSV -------------------------------------------------------------\n",
    "out_dir = Path(\"../../data/new_segments\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "slug = SEGMENT_NAME.lower().replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "out_path = out_dir / f\"{slug}_segments.csv\"\n",
    "\n",
    "export_df.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"Archivo creado: {out_path} | Filas: {len(export_df):,}\")\n",
    "\n",
    "# (Opcional) muestra un sample formateado (no afecta el archivo)\n",
    "# num_cols = [c for c in export_df.columns if export_df[c].dtype.kind in \"fc\"]\n",
    "# display(export_df.head(3).style.format({c: \"{:,.2f}\" for c in num_cols}))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
